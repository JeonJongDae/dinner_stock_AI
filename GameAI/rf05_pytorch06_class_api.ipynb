{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeonJongDae/dinner_stock_AI/blob/main/GameAI/rf05_pytorch06_class_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X-yc7WrJhLJT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = torchvision.datasets.FashionMNIST(root='.', train=True, download=True)\n",
        "x_train = data_train.data / 255\n",
        "y_train = data_train.targets\n",
        "\n",
        "data_valid = torchvision.datasets.FashionMNIST(root='.', train=False, download=True)\n",
        "x_valid = data_valid.data / 255\n",
        "y_valid = data_valid.targets"
      ],
      "metadata": {
        "id": "iuTELZJBitxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a595e638-fee1-4e54-ee29-e57483a1802a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 8463040.30it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 138609.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2601105.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 4145186.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = list(zip(x_train.unsqueeze(1), y_train))\n",
        "dataset_valid = list(zip(x_valid.unsqueeze(1), y_valid))\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=32, shuffle=True, drop_last=True)\n",
        "dataloader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=32)"
      ],
      "metadata": {
        "id": "hozUSBW1ByuA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return input * 2\n",
        "\n",
        "conv = ConvBlock()\n",
        "conv(torch.tensor([1, 2, 3]))\n",
        "#=====================================\n",
        "dummy = torch.randn(32, 10, 28, 28)\n",
        "conv = nn.Conv2d(10, 20, kernel_size=3, padding=1, stride=1)\n",
        "x = conv(dummy)\n",
        "batch = nn.BatchNorm2d(20)\n",
        "x = batch(x)\n",
        "relu = nn.ReLU()\n",
        "x = relu(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.conv = nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding=1, stride=self.stride, bias=False)\n",
        "        self.batch = nn.BatchNorm2d(self.out_channels)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        x = self.conv(input)\n",
        "        x = self.batch(x)\n",
        "        x = torch.relu(x)\n",
        "        return x\n",
        "\n",
        "conv = ConvBlock(10, 20)\n",
        "conv.in_channels\n",
        "z1 = conv(dummy)\n",
        "z2 = conv(dummy)\n",
        "torch.all(z1 == z2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cQbwMNAYl53",
        "outputId": "77de2de0-c2f3-437f-f71f-f8416ba728a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_ch = 10\n",
        "out_ch = 10\n",
        "stride = 1\n",
        "\n",
        "conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, stride=stride)\n",
        "batch1 = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
        "batch2 = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "input = torch.randn(32, in_ch, 28, 28)\n",
        "x = conv1(input) #\n",
        "x = batch1(x)\n",
        "x = torch.relu(x)\n",
        "x = conv2(x)\n",
        "x = batch2(x)\n",
        "if in_ch == out_ch and stride == 1:\n",
        "    x = x + input\n",
        "x = torch.relu(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWYPCHWcsxBe",
        "outputId": "027384fa-40e9-4ba8-bf12-e83804cce325"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 10, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, stride=stride)\n",
        "        self.batch1 = nn.BatchNorm2d(out_ch)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
        "        self.batch2 = nn.BatchNorm2d(out_ch)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input) #\n",
        "        x = self.batch1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batch2(x)\n",
        "        if in_ch == out_ch and stride == 1:\n",
        "            x = x + input\n",
        "        x = torch.relu(x)\n",
        "        return x\n",
        "\n",
        "res = ResBlock(10, 20, 2)\n",
        "res(input).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "JBVmgU8sscr4",
        "outputId": "9d25baec-f387-4931-a78a-d2a916f1d919"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5eaacbbf5306>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-5eaacbbf5306>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0min_ch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mout_ch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (14) must match the size of tensor b (28) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "MoNd8TqwqQxh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataloader_train:\n",
        "    break\n",
        "x.shape, y.shape #(torch.Size([32, 1, 28, 28]), torch.Size([32]))\n",
        "\n",
        "model = nn.Sequential(\n",
        "    ConvBlock(1, 32), \n",
        "    ConvBlock(32, 64, stride=2),\n",
        "    ConvBlock(64, 64),\n",
        "    ConvBlock(64, 128, stride=2),\n",
        "    ConvBlock(128, 128),\n",
        "    # nn.Flatten(),\n",
        "    # nn.Linear(6272, 128),\n",
        "    # nn.ReLU(),\n",
        "    # nn.Linear(128, 10),\n",
        "    nn.AvgPool2d(7, 7),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "\n",
        "model(x).shape\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLqYCMZtC1OR",
        "outputId": "7324f63c-680d-487f-e454-1cefeeb71674"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ConvBlock(\n",
              "    (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (batch): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (1): ConvBlock(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (batch): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (2): ConvBlock(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (batch): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (3): ConvBlock(\n",
              "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (batch): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (4): ConvBlock(\n",
              "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (batch): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (5): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
              "  (6): Flatten(start_dim=1, end_dim=-1)\n",
              "  (7): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.3)"
      ],
      "metadata": {
        "id": "9AEAHcX7I9yi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "kUBhOa_UJrXF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    loss_list = []\n",
        "    acc_list = []   \n",
        "    model.train()\n",
        "    for step, (x, y) in enumerate(dataloader_train):\n",
        "        #1. feed forward (예측 결과를 계산한다.)\n",
        "        pred = model(x.to(device))\n",
        "        #2. loss\n",
        "        loss = loss_fn(pred, y.to(device))\n",
        "        #3. grad\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        #4. model update (opt)\n",
        "        opt.step()\n",
        "\n",
        "        #번외.. 5. accuracy\n",
        "        acc = torch.sum(pred.to('cpu').detach().argmax(dim=1) == y) / len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        acc_list.append(acc.item())\n",
        "        total_loss = round(sum(loss_list) / len(loss_list), 4)\n",
        "        total_acc = round(sum(acc_list) / len(acc_list), 4)\n",
        "\n",
        "        print(f'\\repoch={epoch} step={step} loss={total_loss} acc={total_acc}', end='')\n",
        "    print()\n",
        "    loss_list = []\n",
        "    acc_list = []  \n",
        "    model.eval()\n",
        "    for step, (x, y) in enumerate(dataloader_valid):\n",
        "        #1. feed forward (예측 결과를 계산한다.)\n",
        "        with torch.no_grad():\n",
        "            pred = model(x.to(device))\n",
        "        #2. loss\n",
        "        loss = loss_fn(pred, y.to(device))\n",
        "\n",
        "        #번외.. 5. accuracy\n",
        "        acc = torch.sum(pred.to('cpu').detach().argmax(dim=1) == y) / len(y)\n",
        "        loss_list.append(loss.item())\n",
        "        acc_list.append(acc.item())\n",
        "        total_loss = round(sum(loss_list) / len(loss_list), 4)\n",
        "        total_acc = round(sum(acc_list) / len(acc_list), 4)\n",
        "\n",
        "        print(f'\\r                                                step={step} loss={total_loss} acc={total_acc}', end='')\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kza_yXF0J6ha",
        "outputId": "47fe5de5-cf9f-4819-90a5-15c44c8b9c35"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0 step=1874 loss=1.4236 acc=0.8484\n",
            "                                                step=312 loss=1.3738 acc=0.8841\n",
            "epoch=1 step=1874 loss=1.342 acc=0.9037\n",
            "                                                step=312 loss=1.342 acc=0.8985\n",
            "epoch=2 step=1874 loss=1.321 acc=0.9177\n",
            "                                                step=312 loss=1.326 acc=0.9123\n",
            "epoch=3 step=1874 loss=1.3074 acc=0.9278\n",
            "                                                step=312 loss=1.3179 acc=0.9185\n",
            "epoch=4 step=1874 loss=1.2957 acc=0.9367\n",
            "                                                step=312 loss=1.3202 acc=0.9145\n",
            "epoch=5 step=1874 loss=1.2865 acc=0.9421\n",
            "                                                step=312 loss=1.3109 acc=0.9203\n",
            "epoch=6 step=1874 loss=1.2791 acc=0.9482\n",
            "                                                step=312 loss=1.3091 acc=0.9186\n",
            "epoch=7 step=1874 loss=1.2713 acc=0.9548\n",
            "                                                step=312 loss=1.3102 acc=0.9192\n",
            "epoch=8 step=1874 loss=1.2647 acc=0.96\n",
            "                                                step=312 loss=1.2976 acc=0.929\n",
            "epoch=9 step=1874 loss=1.2586 acc=0.9653\n",
            "                                                step=312 loss=1.3108 acc=0.9231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(128, 1, 1)\n",
        "a.reshape(-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZzw4PRprWlr",
        "outputId": "da09c4d8-3995-462e-9d10-045cba0d5f5d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logit = model(x_valid.unsqueeze(1).to(device))\n",
        "prob = torch.softmax(logit, dim=1)\n",
        "y_pred = torch.argmax(prob, dim=1)\n",
        "y_pred[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTmUoQQIM52y",
        "outputId": "6fa4d99c-158e-4a4c-c632-2ca2da9034b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid[:10]"
      ],
      "metadata": {
        "id": "2pvnVOutNuHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e817f2d-b476-4969-8c25-8e0825963358"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(y_pred == y_valid.to(device)) / len(y_valid.to(device))"
      ],
      "metadata": {
        "id": "6drlIg13N6pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d30d83d-211d-483e-adbb-e98e1a1269f4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9230, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}